\documentclass[12pt]{article}%
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.2cm, right=2.2cm]%
{geometry}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amssymb}
\newenvironment{proof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\begin{document}

\title{Math 774 Homework 3 (V2)}
\author{Edward Kim}
\date{\today}
\maketitle

\subsection*{Problem 1}
\begin{enumerate}
  \item
  \begin{proof}
  Define the character $ch(V) = \sum_n \dim(V_n)t^n$. To show that $V$ is characterized up to isomorphism, we first observe that if $V_1,V_2$ are two $\mathfrak{sl}_2$ representations, then $ch(V_1 \oplus V_2) = ch(V_1) + ch(V_2)$.

  If we set $T = V_1 \oplus V_2$, then expanding the definition:
  $$T_n = \{x \in T \vert h.x = nx\} = \{v_1 + v_2 \in V_1 \oplus V_2 \vert h.x_1 + h.x_2 = n.x_1 + n.x_2 \}$$ shows us that, if $(V_1)_n,(V_2)_n$ are the respective weight-$n$ spaces of $V_1$,$V_2$ then $(V_1)_n + (V_2)_n = T_n$. Hence, $ch(T) = \sum_n \dim(T_n)t^n = \sum_n (\dim((V_1)_n) + \dim((V_2)_n)) t^n = ch(V_1) + ch(V_2)$.

  Finally invoking Weyl's Theorem and Theorem 7.2(c) shows that two representations with the same character must be isomorphic as claimed.
  \end{proof}
  \item
  \begin{proof}
    Let $L = L(m)$ be the unique irreducible representation of dimension $m+1$. We directly calculate $ch(L(m))$ by it's definition and consulting Theorem 7.2:
    $$ ch(L) =  \dim{L_{m}}t^m + \dim{L_{m-2}}t^{m-2} + ... + \dim{L_{-(m-2)}}t^{-(m-2)} + \dim{L_{-m}}t^{-m} $$ $$ = t^m + t^{m-2} + ... + t^{-(m-2)} + t^{-m} $$ \end{proof}
  \item
  \begin{proof}
    The Clebsch-Gordan Formula decomposes the tensor product of $L(m),L(n)$ as follows:
    \begin{gather}
      L(m) \otimes L(n) \cong \bigoplus_k L_k \\
      |n - m| \leq k \leq n + m \\
      n + m - k \in 2 \mathbb{Z}
    \end{gather}
    In light of part one, it suffices to show that both sides have the same character. To begin, we show that $ch(V_1 \otimes V_2) = ch(V_1)ch(V_2)$ for two $\mathfrak{sl}_2$ representations. The proof of this fact stems from a similar argument shown in part one combined with the bilinearity of the tensor product. Since $\dim{(V_1 \otimes V_2)} = \dim{V_1}\dim{V_2}$, the formula immediately follows.

    Assume that $n \leq m$. We now expand the left side:
    $$ L(m) \otimes L(n) = (t^m + t^{m-2} + ... + t^{-(m-2)} + t^{-m})(t^n + t^{n-2} + ... + t^{-(n-2)} + t^{-n}) $$
    and rearrange the product as follows: \newpage
    \begin{gather*}
       L(m) \otimes L(n) = \\
       (t^m + t^{m-2} + ... + t^{-(m-2)} + t^{-m})\cdot t^n + t^{-m}\cdot(t^{n-2} + ... + t^{-n}) + \\
       (t^m + t^{m-2} + ... + t^{-(m-2)})\cdot t^{n-2} + t^{-(m-2)}\cdot(t^{n-4} + ... + t^{-n}) + \\
       .... \\
       t^m \cdot t^{n - 2*(m+1)} + t^{m} \cdot (t^{n - 2*(m+2)} + ... + t^{-n})
    \end{gather*}

    Note that for every row $j$ in the expansion (ordered consecutively from top to bottom), the first multiplictive term gives us elements with exponents from $n + m - 2j$ to $n - m$. The second multiplictive term gives us the remaining elements with exponents from $n-m-2$ to $-(n+m - 2j)$, completing the character for $L(n+m - 2j)$. The proof of the correctness will hinge on an $(n+1) \times (m+1)$ table where the $(i,j)$ cell ($0 \leq i \leq m$,$0 \leq j \leq n$) represents the term $t^{(m-2i)(n-2j)}$ of the product expansion. We cross out the cells each time we see the corresponding term in the expansion. Further details of this argument are posted in the back.

    We deduce from the exponents of the first and last row that the highest and lowest weights of the direct sum decomposition will be $n+m$ and $n-m$ respectively.

    To see that every $k$ in the direct sum decomposition of the tensor product must satisfy Condition 3, observe that every row is of the form $L(n+m - 2j)$ for some $j \leq 0$. To bound $j$, begin by noting that $n+m$ is always a summand of the decompositon. Also, the terms of the last row will have exponenet $n - 2m +m = n-m$ which shows that $j \geq |n-m|$. This bounds $|n-m| \leq j \leq n+m$ as desired.
    \end{proof}

  \item
  \begin{proof}
    We claim that every object in the category of $\mathfrak{sl}_2$ representations is "generated" in the sense that we can define the ring $R$ generated by $L(1)$ with $\oplus$-addition and $\otimes$-multiplication, and every object can be identified with an element in $R$. To begin, Weyl's Theorem tells us that it suffices to see if each $L(n)$ is isomorphic to some element in $R$.

    We will proceed by inducting on the dimension $n+1$ of the irreducible representations. Invoking the Clebsch-Gordan formula, we see that $L(2) \cong L(1) \otimes L(1)$. Now assuming that $n \geq 2$, we once again invoke the Clebsch-Gordon formula to yield:
    $$L(n+1) \oplus L(n-1) \cong L(n) \otimes L(1) \implies $$ $$ L(n+1) \cong L(n) \otimes L(1) - L(n-1) \in R$$ The induction hypothesis guarantees the last inclusion. The same induction argument also shows that each $L(n)$ is uniquely represented in $R$.
  \end{proof}
\end{enumerate}

\subsection*{Problem 2 (Humphreys 7.7)}
\begin{enumerate}
  \item
  \begin{proof}
  As the $L$-actions on $Z(\lambda)$ are linear transformations, we only have to check that the bracket product respects the actions on the $v_i$ :
    $$
      [xy]v_i = xy.v_i - yx.v_i = x.(i+1)v_{i+1} - y.(\lambda - i + 1)v_{i-1} =  $$  $$
      (\lambda - (i+1) + 1)v_i - i(\lambda - i + 1)v_i = (i\lambda - i^2 + \lambda - i)v_i - (i\lambda - i^2 + i)v_i = (\lambda - 2i)v_i = h.v_i $$
    Similarly,
    $$ [hx].v_i = 2x.v_i \quad [hy].v_i = -2y.v_i $$

    If $N$ is a proper $L$-submodule of $Z(\lambda)$, then, by formulas (a)-(c), there must exist at least one $j$ such that basis $v_j = 0$ for all elements in $N$. Then $x.v_j = 0$ making $v_j$ a maximal vector of $N$.
  \end{proof}
  \item
  \begin{proof}
    Let $i = \lambda + 1$, then $x.v_i = (\lambda - i + 1)v_{i-1} = 0.v_{i-1} = 0$, making $v_i$ a maximal vector. Now let $\phi:Z(\mu) \rightarrow Z(\lambda)$ be the map which takes $y^j.v_0 \mapsto y^j.v_i$ for $j \geq 0$. Since $\mu = \lambda - 2i$, we can check directly if this map is indeed a $L$-linear homomorphism:
    $$\phi(h.v_0) = \phi(\mu v_0) = \mu \phi(v_0) = (\lambda - 2i)v_i = h.\phi(v_0) $$
    $$\phi(x.v_0) = 0 = x.v_i = x.\phi(v_0) $$

    Since $v_0 \mapsto v_i$ injectively in respect to the first component, if $v_i = 0$, then $v_0 = 0$. Furthermore, $y^j.v_0 = 0 = y^j.v_i$ for $j \geq 1$. Thus, if $z \in Z(\mu)$ and $\phi(z) = 0$, then $z = 0$ and $\phi$ is a monomorphism.

    Lastly, $\phi(Z(\mu))$ and $Z(\lambda)/\phi(Z(\mu))$ are both irreducible as $L$-submodules. Since $Z(\lambda)/\phi(Z(\mu)) \cong \text{span}_F\{v_0,...,v_{m-1}\}$ which is isomorphic to the irreducible module $L(m)$.

    Also, $\phi(Z(\mu)) \cong Z(\mu)$ as $\phi$ is a monomorphism. If there existed a proper $L$-submodule $P \subset \phi(Z(\mu))$, then $P_0 = \phi^{-1}(P)$ would also be a proper submodule in $Z(\mu)$. If $\mu + 1$ is a not postive integer, then by part (c) below, we would derive a contradiction. Else set $\mu+1 = i_1$.

    We can reiterate this argument with $P_0 \cap \phi_1(Z(\mu_1))$ where $\phi_1: Z(\mu_1) \rightarrow Z(\mu),\mu_1 = \mu - 2i_1$ is once again a monomorphism by our argument above. However, we must check that indeed $P_0 \cap \phi_1(Z(\mu_1)) \neq \emptyset$. Since both $P_0$ and $\phi_1(Z(\mu_1))$ are proper submodules of $Z(\mu)$, part one shows us that there exists maximal vectors $v_{k_1},v_{k_2} \in Z(\mu)$ for $P_0,\phi_1(Z(\mu_1))$ respectively. By taking the largest of $k_1,k_2$, we see that one encompasses the other and their intersections cannot be empty.

    Continue this until we reach a point where
    $ \mu_{k} + 1$ is no longer a positive integer. It must follow that $P_{k}$ is a proper $L$-submodule of $Z(\mu_{k})$ which contradicts its irreducibility (proven in (c)).
  \end{proof}
  \item
  \begin{proof}
    If $\lambda + 1$ is not a positive integer, then formulas (a)-(c) of Lemma 7.2 show that no subset of the basis vectors can be closed underneath the actions of $x,y,h$. In particular, there exists no $v_r \neq 0$ such that $x.v_r = 0$ and $h.v_r = 0$. The last statement holds as $\lambda + 1 \not\in \mathbb{Z}_+$ implies $\lambda \not\in \mathbb{Z}_+$, so $\lambda \neq 2r$ for any $r \in \mathbb{N}$.
    Therefore, no proper submodule can exist within $Z(\lambda)$, showing irreducibility.
  \end{proof}
\end{enumerate}

\subsection*{Problem 3 (Humphreys 8.3)}
\begin{proof}
We will first show that the Killing Form restricted to the maximal toral algebra for any semi-simple Lie algebra will be $\kappa(l,r) = \sum_{\alpha \in \Phi} \alpha(l)\alpha(r)$.

We begin with the fact that all elements in $ad_L(H)$ are simultaneously diagonalizable, and we can express $ad_L(l)$ and $ad_L(r)$ as diagonal matrices in some suitable basis. By the root space decomposition, we can find a set of basis elements for $ad_L(L)$ such that we can order the set according to the direct sum of $H$ and the $L_{\alpha}$.

By definition, $L_{\alpha} = \{ x\in L \vert ad_L(h)(x) = \alpha(h)x\}$. Thus, the matrices of $ad_L(l),ad_L(r)$ will have $\alpha(l)$,$\alpha(r)$ in the entry corresponding to $x \in L_{\alpha}$. Since $\dim{L_{\alpha}} = 1$, there will only be one such entry. Since $H$ is abelian, the entries corresponding to all elements in $H$ will have a zero. Computing the trace of the $ad_L(l)ad_L(r)$ will yield the formula above as required.

Now we will apply this formula to the specific case where $H$ is the set of all diagonal matrices with trace zero. Consider two basis matrices of $h_1 = e_{i,i} - e_{i+1,i+1}$, $h_2 = e_{j,j} - e_{j+1,j+1}$. By Problem 1.6, we know that the distinct eigenvalues of $ad(e_{i,i}- e_{i+1,i+1})$ will be $-2,0,2$. Thus, the roots $\alpha \in \Phi$ can only take the values $-2,0,2$. By the form derived above: $\kappa(h_1,h_2) \equiv 0 \text{ }  (\mathrm{mod} 4)$
\end{proof}

\subsection*{Problem 4 (Humphreys 8.10)}
\begin{proof}
  To see that no four-dimensional semi-simple Lie algebras exist, we note that if $L$ is such a Lie algebra, then $L \neq H$ as $H$ is abelian. Thus, there must exist at least one set of roots $\alpha,-\alpha$ such that $S_{\alpha} = \{x_{\alpha},y_{\alpha},h_{\alpha}\}$ for $x_{\alpha} \in L_{\alpha}, y_{\alpha} \in L_{-\alpha}, h_{\alpha} = [x_{\alpha}y_{\alpha}] \in H$. Further analysis shows that there can only be one set of roots as each pair of roots adds two dimensions, and each pair determines a unique $t_{\alpha}$. Let $L = H \oplus L_{\alpha} \oplus L_{-\alpha}$ be the corresponding root space decomposition of $L$. As $\dim H = 2$, let $H = \text{span}_F\{h_1,h_2\}$. We consider the value $t_{\alpha}$ takes in cases.

  Without loss of generality, take the first case to be $t_{\alpha} = h_1$. Recall that $\Phi = \{\alpha,-\alpha\}$ spans $H^*$; in particular, the standard dual basis $e_1,e_2 \in H^*$ must be linear combinations of $\alpha$. Also, $\alpha(h_1) = \alpha_(t_{\alpha}) \neq 0$ can be scaled such that $\alpha(h_1) = 1$. By the definition of $e_1$ and the fact that $\Phi$ spans $H^*$:
  \begin{gather*}
   e_1(h_1) = 1 = \alpha(h_1) \\
   e_1(h_2) = 0 = \alpha(h_2)
 \end{gather*}
 However $e_2$ must also be some linear combination of $\alpha$ which forces that:
 \begin{gather*}
   e_2(h_2) = 1 = \alpha(h_2) \\
   e_2(h_1) = 0 = \alpha(h_1)
 \end{gather*}
 which contradicts our finding above.
 The second case would be that $t_{\alpha} = ah_1 + bh_2$ for $a,b \in F$. We would get a similar contradiction as above since $\alpha$ would have to span both $e_1,e_2$ which take different values on $h_1,h_2$. Since $\alpha(ah_1 + bh_2) = a \alpha(h_1) + b\alpha(h_2) = 1$, the case where either $\alpha(h_1),\alpha(h_2)$ is zero or both are nonzero contradict our findings above once again. Thus, $\dim L \neq 4$.


 Suppose now that $\dim L = 5$. We imitate the argument above and reason that there must exist at least one pair of roots $(\alpha,-\alpha)$ and at most one pair of roots. The latter statement derives from the observation that two distinct pair of roots, say $(\alpha,-\alpha),(\beta,-\beta)$, would force $\dim H = 1$ which would force $t_{\alpha} = t_{\beta} \implies \alpha = \beta$, contradiction.
 Again, we take $L = H \oplus L_{\alpha} \oplus L_{-\alpha}$ with $H = \text{span}_F\{h_1,h_2,h_3\}$. The same analysis as four-dimensional case shows that $\alpha$ on its own cannot span all three $e_1,e_2,e_3 \in H^*$ standard dual basis vectors, showing that $\dim L \neq 5$.

 Finally, we consider $\dim L = 7$. $L$ can have at most two distinct pairs of roots as three pairs would force $\dim H = 1$ and we would have a contradiction on the uniqueness of the $t_{\gamma}, \gamma \in \Phi$. Suppose that there existed two distinct pairs of roots $(\alpha,-\alpha),(\beta,-\beta)$. This leaves that $\alpha,\beta$ must span $H^*$ where $\dim H^* = 3$. However, $\alpha,\beta$ can only span a two-dimensional subspace of $H^*$ at best.

 Similarly, having only one pair of roots will give us that a one-dimensional subspace of $H^*$ spans the 5-dimensional $H^*$, contradiction. These conclusions give us the required result that $\dim L \neq 4,5,7$ if $L$ is semi-simple.
\end{proof}

\subsection*{Problem 5 (Humphreys 9.2)}
\begin{proof}
  Showing that $\Phi^{\vee}$ is a root system follows from the fact that $\Phi$ is itself a root system. Axioms (R1)-(R3) easily follow from $\Phi$. (R4) follows from the fact that
  $\langle \beta^{\vee},\alpha^{\vee} \rangle = \langle \alpha,\beta \rangle \in \mathbb{Z}$. The map which takes $\sigma_{\alpha} \mapsto \sigma_{\alpha^{\vee}}$ induces the desired isomorphism between $\mathcal{W}$ and $\mathcal{W^{\vee}}$ as $\sigma_{\alpha^{\vee}}$ yields the same reflection as $\sigma_{\alpha}$. Furthermore,
  $$ \langle \alpha^{\vee},\beta^{\vee} \rangle = \frac{2(\alpha^{\vee},\beta^{\vee})}{(\beta^{\vee},\beta^{\vee})} = \frac{2\frac{2}{(\alpha,\alpha)}(\alpha,\beta)}{\frac{2}{(\beta,\beta)}(\beta,\beta)} = \frac{2(\beta,\alpha)}{(\alpha,\alpha)} = \langle \beta,\alpha\rangle$$
  The last portion is hand-drawn on the back. Since $\Phi^{\vee}$ scales the roots in $\Phi$, the angles between the roots will not change. To see the lengths: We use the formula above:
  $$ \langle \beta^{\vee}, \alpha^{\vee} \rangle = 2 \frac{||\beta^{\vee}||}{||\alpha^{\vee}||} \cos \theta = \langle \alpha, \beta \rangle = 2 \frac{||\alpha||}{||\beta||} \cos \theta \implies $$
  $$ \frac{||\beta^{\vee}||}{||\alpha^{\vee}||} = \frac{||\alpha||}{||\beta||} $$
  This shows that the length ratios are flipped in respect to the ratios seen between roots in $\Phi$ (see Table 1).
\end{proof}

\subsection*{Problem 6 (Humphreys 9.3)}
\begin{proof}
  We show that $\tau = \sigma_{\alpha}\sigma_{\beta}$ is equivalent to the rotation of $\Phi$ by $2\phi$ where $\phi$ is the smallest positive angle between $\beta,\alpha$.
  Suppose $\alpha$ is situated at zero degrees. $\sigma_{\beta}(\alpha)$ rotates $\alpha$ by $\pi + 2\phi$ degrees. Reflecting $\sigma_{\beta}(\alpha)$ by $\sigma_{\alpha}$ adds $2(\frac{\pi}{2} - 2\phi)$ degrees, giving us that resulting degree of $\alpha$ is:
  $$(\pi + 2\phi) + 2(\frac{\pi}{2} - 2\phi) = -2\phi $$
  A similar argument for $\beta$ reveals that $\tau(\beta)$ has degree $-\phi$ which aligns with a $-2\phi$ rotation from $\phi$.

  If we take $\alpha,\beta$ to be the basis roots of $\Phi$, we see that $\tau$ rotates all $\gamma \in \Phi$ by $-2\phi$ degrees. Hence, the orders of $\phi = \frac{\pi}{2},\frac{\pi}{3},\frac{\pi}{4},\frac{\pi}{6}$ will be $2,3,4,6$ respectively as these orders induce a full rotation of $\Phi$. \end{proof}

\subsection*{Problem 7 (Humphreys 9.4)}
\begin{proof}
From Problem 6, we know the period of the rotation element $\tau = \sigma_{\alpha}\sigma_{\beta}$ in respect to a root say $\gamma \in \Phi$. Furthermore, each root $\gamma$ has its own reflection map such that $\sigma_{\gamma}^2 = id_{\Phi}$ and $\sigma\tau\sigma = \tau^{-1}$ for all of the corresponding Weyl Groups. Writing this out: $\tau^n = 1$, $\sigma^2 = 1$, $\sigma\tau\sigma = \tau^{-1}$ where $n$ is the order of the rotation subgroup found in Problem 6. This is precisely the generators and relations for $D_n$.

Since an isomorphism of two root systems $(\Phi,E),(\Phi',E')$ induces an isomorphism between their respective Weyl Groups $\mathcal{W},\mathcal{W}'$, it suffices to show that every rank two root system is isomorphic to one of $A_1 \times A_1,A_2,B_2,G_2$. The argument presented in Section 9.2 shows that the angle between the two basis roots $\alpha,\beta$ are exhaustively listed in Table 1 as no other angles $\theta$ will yield $4\cos^2(\theta) \in \mathbb{Z}_+$. This in turn gives us the relative ratios between $||\beta||,||\alpha||$ in Table 1. Applying $\sigma_{\alpha},\sigma_{\beta}$ successively will exactly give us one of the four diagrams, depending on $\theta$. \end{proof}
\end{document}
